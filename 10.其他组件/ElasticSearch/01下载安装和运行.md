### docker安装（推荐！强烈推荐）

- 下载ElasticSearch相关镜像

```
#搜索镜像
docker search -f "is-official=true" elasticsearch

#拉取镜像
docker pull elasticsearch:7.4.2

#运行
# -e 表示容器内部的环境变量
# discovery.type=single-node 设置为单节点运行
# -p 表示端口映射
# --name 设置容器名称
# -d 表示后台运行该容器，并返回容器的ID
docker run --name es -e "discovery.type=single-node" -p 9200:9200 -p 9300:9300 -d elasticsearch:7.4.2

#校验是否成功启动
curl http://192.168.73.134:9200
```

- 安装Kibana

```
# 查找镜像
docker search -f "is-official=true" kibana

# 下载镜像
docker pull kibana:7.4.2

#运行容器
docker run --name kibana -p 5601:5601 -d kibana:7.4.2

#查看ElasticSearch容器内ip
docker inspect es
找到IPAddress:后的ip

#进入kibana容器进行配置
docker exec -it kibana /bin/bash
vi config/kibana.yml
#修改elasticsearch.hosts: 后的elasticsearch为刚刚复制的ip
#并且追加如下配置
xpack.security.encryptionKey: "122333444455555666666777777788888888"
xpack.reporting.encryptionKey: "122333444455555666666777777788888888"

#可以追加如下配置，修改kibana为中文
i18n.locale: "zh-CN"

#重启docker
docker restart kibana

#访问
http://192.168.73.134:5601/
```





### 下载

下载地址：[elasticsearch-7.3.2-linux-x86_64.tar.gz](https://artifacts.elastic.co/downloads/elasticsearch/elasticsearch-7.3.2-linux-x86_64.tar.gz)

elasticsearch历史版本：https://www.elastic.co/cn/downloads/past-releases#elasticsearch
kibana历史版本：https://www.elastic.co/cn/downloads/past-releases#kibana

### 安装

```
#解压到当前目录
tar -zxf elasticsearch-7.3.2
#移动到/usr/local/es
mv -zxf elasticsearch-7.3.2 /usr/local/es
```

### 配置

- 修改ElasticSearch 应用的所有者：ElasticSearch不允许root用户启动，所以我们需要江ElasticSearch应用的所有者修改为其他用户。

  ```
  #修改es文件夹的所有者为test
  chown -R test.test /usr/local/es
  ```

- vi config/elasticsearch.yml

  ```
  增加： network.host: 0.0.0.0
  ```

#### 其他配置参数

elasticsearch.yml

```yml
# 配置elasticsearch的集群名称，默认是elasticsearch。elasticsearch会自动发现在同一网段下的集群名为elasticsearch的主机，如果在同一网段下有多个集群，就可以用这个属性来区分不同的集群。生成环境时建议更改。
cluster.name: elasticsearch

# 节点名，默认随即指定一个name列表中名字，该列表在elasticsearchdjar包中的config文件夹中
node.name: "Franz Kafka"

# 指定该节点是否有资格被选举成为node，默认是true，elasticsearch默认集群中的第一台启动的机器为master，如果这台机器挂了就会选举新的master
node.master: true

# 指定该节点是否存储索引数据，默认为true。如果节点配置node.mater: false并且node.data: false，则该节点将起到负载均衡的作用
node.data: ture

# 设置默认索引分片个数，默认为5片，
index.number_of_shards: 5

# 设置默认索引副本个数，默认一个副本。此处的1个副本是指index.number_of_shards的一个完全拷贝，默认5个分片1个拷贝，即总分片数为10
index.number_of_replicas: 1

# 设置配置文件的存储路径，默认是es根目录下的config文件夹
path.conf: /path/to/conf

# 设置索引数据的存储路径，默认是es根目录下的data文件夹，可以设置多个存储路径，用逗号隔开
path.data: /path/to/data1,/path/to/data2

# 设置临时文件的存储路径，默认是es根目录下的work文件夹
path.work: /path/to/work

# 设置日志文件的存储路径，默认是es根目录下的logs文件夹
path.logs: /path/to/logs

# 设置插件的存放路径，默认是es跟目录下的plugins文件夹
path.plugins: /path/to/plugins

# 设置true来锁住内存。因为当jvm开始swapping时es效率也会降低，要保证他不swap，可以把ES_MIN_MES和ES_MAX_MEM两个环境变量设置为同一个值，来保证机器有足够的内存分配给es。同时也要允许elasticsearch的进程可以锁住内存，linux下可以通过ulimit -l unlimited命令
bootstrap.mlockall: true

# 设置绑定的ip地址，可以是ipv4或者ipv6的，默认为0.0.0.0
network.bind_host: 192.168.0.1

# 设置其他节点和该节点交互的ip地址，如果不设置，会自动判断，值必须是一个真实的ip
network.publish_host: 192.168.0.1

# 同时设置bind_host和publish_host上面的两个参数
network.host: 192.168.0.1

# 设置节点间交互的tcp端口，默认是9300
transport.tcp.port: 9300

# 设置是否压缩tcp传输时的数据，默认为false，不压缩
transport.tcp.compress: ture

# 设置对外服务的http端口，默认是9200
http.port: 9200

# 设置内存的最大容量，默认100mb
http.max_content_length: 100mb

# 是否使用http协议对外提供服务，默认为true，开启
http.enabled: false

# gateway的类型，默认为local即为本地文件系统，可以设置为本地文件系统，分布式文件系统，hadoop的HDFS和amazon的s3服务器，其他文件系统的设置。
gateway.tape: local

# 设置集群中N个节点启动时进行数据恢复，默认为1
gateway.recover_after_nodes: 1

# 设置初始化数据恢复进程的超时时间，默认是5分钟。
gateway.recover_after_time: 5m

# 设置这个集群中节点的数量，默认为2，一旦这N个节点启动，就会进行数据修复。
gateway.expected_node: 2

# 初始化数据恢复时，并发恢复线程个数，默认为4
cluster.routing.allocation.node_initial_primaries_recoveries: 4

# 添加删除节点或负载均衡时，并发挥父线程的个数，默认为4
cluster.routing.allocation.node_concurrent_recoveries: 2

# 设置数据恢复时限制的带宽，如100mb，默认为0，无限制
indices.recovery.max_size_per_sec: 0

# 设置这个参数来限制从其他分片恢复数据时，最大同时打开并发流的个数，默认为5
indices.recovery.concurrent_streams: 5

# 设置这个参数来保证集群中的节点可以知道其他N个有master资格的节点。默认为1，对于大一点的集群来说，可以设置为2-4
discovery.zen.minimum_master_nodes: 1

# 设置集群中自动发现其他节点时ping连接超时时间，默认为3秒，对于比较差的网络环境可以高点的值来防止自动发现时出错。
discovery.zen.ping.timeout: 3s

# 设置是否打开多播发现节点，默认是true。
discovery.zen.ping.multicast.enabled: false

# 设置集群中master节点的初始化列表，可以通过这些节点来自动发现新加入集群的节点。
discovery.zen.ping.unicast.hosts: ["host1","host2:port1","host3 [portX-portY]"]

# 配置es服务器的执行查询操作时所用线程池，fix固定线程数的线程池
threadpool:
	search: 
		type: fixed
		min: 60
		max: 80
		queue_size: 1000

# 索引存储在内存中（实际并不会比正常快多少）
index.store.type: memory

# 禁止自动创建mapping。默认情况下，es可以根据数据类型自动创建mapping。配置为false后，禁止自动创建mapping的行为
index.mapper.dynamic: false

# 不能查找没有mapping中定义的属性
index.query.parse.allow_unmapped_fields: false
```



### 启动

前台启动

```
cd /usr/local/es/bin
./elasticsecarcdarch

ctrl + c关闭
```

后台启动

```
/usr/local/es/bin/elasticsearch -d

后台关闭
#方法一
jps 命令查看 ElasticSearch 线程的编号kill -9 ElasticSearch 线程编号
#方法二：
ps -ef | grep elastic
kill -9 pid
```

浏览器访问ip:9200端口，如果能够看到一个json则表示访问成功，无法访问有可能是因为防火墙未开放9200端口

### 可能遇到的问题

ERROR: [3] bootstrap checks failed
[1]: max file descriptors [4096] for elasticsearch process is too low, increase to at least [65536]

```
vi /etc/security/limits.conf
追加如下内容：
* soft nofile 65536
* hard nofile 65536
```

[2]: memory locking requested for elasticsearch process but memory is not locked

```
vi /etc/sysctl.conf
#追加如下内容
vm.max_map_count=655360
#保存后执行
sysctl -p
```

[3]: max virtual memory areas vm.max_map_count [65530] is too low, increase to at least [262144]

```
vim /etc/security/limits.d/90-nproc.conf 将2048改为4096或更大
```

[1]: the default discovery settings are unsuitable for production use; at least one of [discovery.seed_hosts, discovery.seed_providers, cluster.initial_master_nodes] must be configured

```
vim config/elasticsearch.yml

#添加配置
discovery.seed_hosts: ["127.0.0.1"]
cluster.initial_master_nodes: ["node-1"]
```





## Kibana（最好和ElasticSearch相同版本）

- 官网下载：[Kibana](https://www.elastic.co/cn/downloads/kibana)

```
tar –zxvf kibana-7.3.2-linux-x86_64.tar.gz –C /run/
#给test用户赋权
cd /run/kibana-7.3.2-linux-x86_64/
chown -R test:test kibana-7.3.2-linux-x86_64
cd /run/kibana-7.3.2-linux-x86_64/config
vi kibana.yml
```

- 添加如下配置

  ```
  #配置本机ip
  server.port: 5601
  server.host: "192.168.73.134"
  
  #配置es集群url
  elasticsearch.hosts: ["http://192.168.73.134:9200"]
  ```

- 运行Kibana

```
cd ../bin
./kibana &
```



- wget下载并安装

```
wget https://artifacts.elastic.co/downloads/kibana/kibana-7.17.3-x86_64.rpm

yum install -y localinstall kibana-7.17.3-x86_64.rpm
```

修改配置文件：

vi /etc/kibana/kibana.yml

```
#配置本机ip
server.host: "192.168.252.129"
#配置es集群url
elasticsearch.url: "http://192.168.252.129:9200"
```

